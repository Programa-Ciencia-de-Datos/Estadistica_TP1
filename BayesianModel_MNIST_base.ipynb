{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajo práctico 1: Bayes Ingenuo\n",
    "---\n",
    "*Estudiantes:* \n",
    "- Dennis Luna\n",
    "- Graciela Rivera\n",
    "- Luis E. Vargas \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *I Sección: Implementación de la clasificación multi-clase con Bayes ingenuo*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga de las imágenes- mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train gray dimensions torch.Size([784, 600])\n",
      "train bin dimensions  torch.Size([784, 600])\n",
      "train labels  600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def binarize_image(image_tensor):\n",
    "    image_tensor[image_tensor > 0.5] = 1\n",
    "    image_tensor[image_tensor <= 0.5] = 0\n",
    "    return image_tensor\n",
    "\n",
    "def imshow(image_tensor):\n",
    "    im = plt.imshow(image_tensor.numpy(), cmap = 'gray')\n",
    "    plt.show()\n",
    "       \n",
    "def load_single_image(path = \"src_base/mnist_dataset/train\", img_index=1, mode=\"bin\"):\n",
    "    #Open up the dataset\n",
    "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
    "    #print(dataset)\n",
    "    list_images = dataset.imgs\n",
    "    pair_path_label = list_images[img_index]\n",
    "    new_image = Image.open(pair_path_label[0]) \n",
    "    new_image_plain = None\n",
    "    \n",
    "    if(mode == \"bin\"):\n",
    "        new_image_tf = TF.to_tensor(new_image).squeeze() #Return tensor in range [0.0 - 1.0]\n",
    "        new_image_bin = binarize_image(new_image_tf)\n",
    "        new_image_plain = new_image_bin.view(new_image_bin.shape[0] * new_image_bin.shape[1])\n",
    "    elif(mode == \"gray\"):\n",
    "        new_image_gray = TF.pil_to_tensor(new_image).squeeze() #Return tensor in grayscale\n",
    "        new_image_plain = new_image_gray.view(new_image_gray.shape[0] * new_image_gray.shape[1])\n",
    "    else:\n",
    "        print(\"\\n-E- Modo seleccionado invalido\\n\")\n",
    "        \n",
    "    return(new_image_plain)\n",
    "        \n",
    "def load_dataset(path = \"src_base/mnist_dataset/train\"):\n",
    "    #Open up the dataset\n",
    "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
    "    #print(dataset)\n",
    "    list_images = dataset.imgs\n",
    "    #print(list_images)\n",
    "    train_data_tensor_bin  = None \n",
    "    train_data_tensor_gray = None\n",
    "    labels_training = []\n",
    "    first_tensor = True\n",
    "    #list_images_training =  set(data_labeled.train_ds.x.items)\n",
    "    #print(list_images)\n",
    "    for i in range(len(list_images)):\n",
    "        pair_path_label = list_images[i]\n",
    "        image = Image.open(pair_path_label[0])        \n",
    "\n",
    "        x_tensor = TF.to_tensor(image).squeeze() #Return tensor in range [0.0 - 1.0]\n",
    "        x_tensor_gray = TF.pil_to_tensor(image).squeeze() #Return tensor in grayscale\n",
    "        x_tensor_bin = binarize_image(x_tensor)\n",
    "               \n",
    "        #plt.figure()\n",
    "        #plt.imshow(x_tensor_bin)\n",
    "        x_tensor_bin_plain = x_tensor_bin.view(x_tensor_bin.shape[0] * x_tensor_bin.shape[1], -1)\n",
    "        x_tensor_gray_plain = x_tensor_gray.view(x_tensor_gray.shape[0] * x_tensor_gray.shape[1], -1)\n",
    "        #print(\"tensor \", x_tensor_bin_plain)\n",
    "        #test dataset case        \n",
    "        #if(\"train\" in pair_path_label[0]):\n",
    "        labels_training += [pair_path_label[1]]\n",
    "        #print(pair_path_label)\n",
    "        if(first_tensor):\n",
    "            first_tensor = False\n",
    "            train_data_tensor_bin = x_tensor_bin_plain\n",
    "            train_data_tensor_gray = x_tensor_gray_plain\n",
    "        else:\n",
    "            train_data_tensor_bin = torch.cat((train_data_tensor_bin, x_tensor_bin_plain), 1)  \n",
    "            train_data_tensor_gray = torch.cat((train_data_tensor_gray, x_tensor_gray_plain), 1)\n",
    "    return (train_data_tensor_bin, train_data_tensor_gray, torch.tensor(labels_training))       \n",
    "\n",
    "(train_data_tensor_bin, train_data_tensor_gray, labels_training) = load_dataset()\n",
    "\n",
    "print(\"train gray dimensions\", train_data_tensor_gray.shape)\n",
    "print(\"train bin dimensions \", train_data_tensor_bin.shape)\n",
    "print(\"train labels \", len(labels_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_m_0_given_k_acc =  torch.Size([784, 10])\n",
      "p_m_1_given_k_acc =  torch.Size([784, 10])\n",
      "p_t_tensor_acc =  torch.Size([10])\n",
      "mu_given_k_acc =  torch.Size([784, 10])\n",
      "sigma_given_k_acc =  torch.Size([784, 10])\n"
     ]
    }
   ],
   "source": [
    "def evaluate_gaussian(mu, sigma, x):\n",
    "    coef_norm = 1 / (torch.sqrt(torch.tensor(2.0 * torch.pi * sigma ** 2)))\n",
    "    return coef_norm * torch.exp(torch.tensor(-0.5*((mu - x)/sigma )** 2))\n",
    "\n",
    "def evaluate_gaussian_log(mu, sigma, x_tensor):\n",
    "    M = x_tensor.shape[1]\n",
    "    summation = -1 / (2.0 * torch.pi * sigma ** 2) * ((x_tensor - mu) ** 2).sum(dim=1).view(x_tensor.shape[0], -1)\n",
    "    p_gaussian = summation - (M/2 * torch.log(torch.tensor(2 * torch.pi))) - (M * torch.log(sigma))\n",
    "    return p_gaussian\n",
    "    \n",
    "def train_model(train_data_tensor_bin, train_data_tensor_gray, labels_training, num_classes = 10):\n",
    "\n",
    "    first_tensor = True\n",
    "    p_t_tensor_acc = None\n",
    "    p_m_1_given_k_acc = None\n",
    "    p_m_0_given_k_acc = None\n",
    "    mu_given_k_acc = None\n",
    "    sigma_given_k_acc = None\n",
    "    #gaussian_given_k_acc = None\n",
    "    #print(train_data_tensor_gray[650, 0:60])\n",
    "    \n",
    "    for k in range(num_classes):\n",
    "        # Filtra train_data_tensor por clase para dataset binarizado y en escala de grises\n",
    "        train_data_tensor_bin_per_k = train_data_tensor_bin[:, labels_training == k].type(torch.int64)\n",
    "        train_data_tensor_gray_per_k = train_data_tensor_gray[:, labels_training == k].type(torch.float64)\n",
    "        #print(train_data_tensor_bin_per_k)\n",
    "        #print(train_data_tensor_gray_per_k)\n",
    "        \n",
    "        # D = cantidad de filas (784 pixeles)\n",
    "        # N = cantidad de columnas (600 imágenes)\n",
    "        D, N = train_data_tensor_bin.shape\n",
    "        \n",
    "        # Estimacion de probabilidad a priori\n",
    "        p_t_tensor = torch.tensor([train_data_tensor_bin_per_k.shape[1] / N])\n",
    "        #print(p_t_tensor)\n",
    "        \n",
    "        # Estimacion de verisimilitud para cada pixel por clase\n",
    "        p_m_1_given_k = ((train_data_tensor_bin_per_k == 1).sum(dim=1)/train_data_tensor_bin_per_k.shape[1])+1e-12\n",
    "        #print(p_m_pix_val_given_k)\n",
    "        \n",
    "        # Transforma tensor de verisimilitud a una sola columna\n",
    "        p_m_1_given_k = p_m_1_given_k.view(p_m_1_given_k.shape[0], -1)\n",
    "        #print(p_m_pix_val_given_k)\n",
    "    \n",
    "        # Calculo de media y desviacion estandar\n",
    "        mu_given_k = torch.mean(train_data_tensor_gray_per_k, dim=1)\n",
    "        sigma_given_k = torch.std(train_data_tensor_gray_per_k, dim=1)+1e-12\n",
    "        #print(mu_given_k.shape)\n",
    "        #print(sigma_given_k.shape)\n",
    "        \n",
    "        # Transforma tensor de mu y sigma a una sola columna\n",
    "        mu_given_k = mu_given_k.view(mu_given_k.shape[0], -1)\n",
    "        sigma_given_k = sigma_given_k.view(sigma_given_k.shape[0], -1)\n",
    "        #print(mu_given_k)\n",
    "        \n",
    "        # Estimacion de funcion de densidad de probabilidad\n",
    "        #gaussian_given_k = evaluate_gaussian_log(mu_given_k, sigma_given_k, train_data_tensor_gray_per_k)\n",
    "        #print(gaussian_given_k)\n",
    "    \n",
    "        if(first_tensor):\n",
    "            first_tensor = False\n",
    "            p_m_1_given_k_acc = p_m_1_given_k\n",
    "            p_t_tensor_acc = p_t_tensor\n",
    "            mu_given_k_acc = mu_given_k\n",
    "            sigma_given_k_acc = sigma_given_k\n",
    "            #gaussian_given_k_acc = gaussian_given_k\n",
    "        else:\n",
    "            p_m_1_given_k_acc = torch.cat((p_m_1_given_k_acc, p_m_1_given_k), 1)\n",
    "            p_t_tensor_acc = torch.cat((p_t_tensor_acc, p_t_tensor), 0)\n",
    "            mu_given_k_acc = torch.cat((mu_given_k_acc, mu_given_k), 1)\n",
    "            sigma_given_k_acc = torch.cat((sigma_given_k_acc, sigma_given_k), 1)\n",
    "            #gaussian_given_k_acc = torch.cat((gaussian_given_k_acc, gaussian_given_k), 1)\n",
    "\n",
    "    # Saca complemento de p_m_1_given_k_acc\n",
    "    p_m_0_given_k_acc = 1 - p_m_1_given_k_acc\n",
    "    \n",
    "    print(\"p_m_0_given_k_acc = \", p_m_0_given_k_acc.shape)\n",
    "    print(\"p_m_1_given_k_acc = \", p_m_1_given_k_acc.shape)\n",
    "    print(\"p_t_tensor_acc = \", p_t_tensor_acc.shape)\n",
    "    print(\"mu_given_k_acc = \", mu_given_k_acc.shape)\n",
    "    print(\"sigma_given_k_acc = \", sigma_given_k_acc.shape)\n",
    "    #print(\"gaussian_given_k_acc = \", gaussian_given_k_acc.shape)\n",
    "        \n",
    "    return (list([p_m_0_given_k_acc, p_m_1_given_k_acc]), mu_given_k_acc, sigma_given_k_acc, p_t_tensor_acc)\n",
    "            \n",
    "        \n",
    "p_m_pix_val_given_k, mu_all, sigma_all, p_t_tensor = train_model(train_data_tensor, train_data_tensor_gray, labels_training)\n",
    "        \n",
    "#train model by calculating the prior probabilities\n",
    "#(p_m_pix_val_given_k, p_t_tensor) = train_model(train_data_tensor, labels_training)\n",
    "#print(\"p_m_pix_val_given_k size \", p_m_pix_val_given_k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test Bernoulli Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-71.3250),\n",
       " [tensor(-453.0000),\n",
       "  tensor(-71.3250),\n",
       "  tensor(-174.6764),\n",
       "  tensor(-181.1103),\n",
       "  tensor(-276.7626),\n",
       "  tensor(-163.3922),\n",
       "  tensor(-188.7553),\n",
       "  tensor(-227.8077),\n",
       "  tensor(-167.0967),\n",
       "  tensor(-226.6600)])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_bernoulli(input_torch, p_m_pix_val_given_k, p_t_tensor, num_classes = 10):\n",
    "    #assumes that the input comes in a row    \n",
    "    input_torch_single_column = input_torch.view(input_torch.shape[0], -1)\n",
    "  \n",
    "    p_t_k_given_m = [] \n",
    "    for k in range(num_classes):\n",
    "        # Extraer probabilidades de acuerdo al input_torch nuevo para cuando pixel es 0\n",
    "        p_m_0_extracted = torch.log(p_m_pix_val_given_k[0][:,k].unsqueeze(dim=1)[input_torch_single_column == 0])\n",
    "        # Estima log para todas las probabilidades extraidas\n",
    "        p_m_0_estimated = p_m_0_extracted.sum(dim=0) \n",
    "        # Extraer probabilidades de acuerdo al input_torch nuevo para cuando pixel es 1\n",
    "        p_m_1_extracted = torch.log(p_m_pix_val_given_k[1][:,k].unsqueeze(dim=1)[input_torch_single_column == 1])\n",
    "        # Estima log para todas las probabilidades extraidas\n",
    "        p_m_1_estimated = p_m_1_extracted.sum(dim=0) \n",
    "        # Estimacion de la probabilidad posterior\n",
    "        p_t_k_given_m.append(p_m_0_estimated + p_m_1_estimated + torch.log(p_t_tensor[k]))\n",
    "        \n",
    "    scores_classes = p_t_k_given_m\n",
    "    predicted_label = max(p_t_k_given_m)\n",
    "    return (predicted_label, scores_classes)\n",
    "\n",
    "new_image_ber = load_single_image(img_index = 65, mode=\"bin\") #Numero 1\n",
    "#input_torch = torch.bernoulli(new_image)\n",
    "#print(input_torch)\n",
    "test_model_bernoulli(new_image_ber, p_m_pix_val_given_k, p_t_tensor, num_classes = 10)\n",
    "\n",
    "#(predicted_label, scores_classes) = test_model(train_data_tensor[:, 500], p_m_pix_val_given_k, p_t_tensor)\n",
    "#print(\"predicted_label \", predicted_label)\n",
    "#print(\"real label \", labels_training[500])\n",
    "#acc = test_model_batch(train_data_tensor, labels_training, p_m_pix_val_given_k, p_t_tensor)\n",
    "#print(\"Model accuracy \", acc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test Gaussian Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.8794e+26, dtype=torch.float64),\n",
       " [tensor(-7.5324e+26, dtype=torch.float64),\n",
       "  tensor(-3.2579e+28, dtype=torch.float64),\n",
       "  tensor(-7.1195e+26, dtype=torch.float64),\n",
       "  tensor(-3.5708e+27, dtype=torch.float64),\n",
       "  tensor(-1.8794e+26, dtype=torch.float64),\n",
       "  tensor(-1.9629e+26, dtype=torch.float64),\n",
       "  tensor(-4.8326e+28, dtype=torch.float64),\n",
       "  tensor(-1.5000e+27, dtype=torch.float64),\n",
       "  tensor(-8.4490e+26, dtype=torch.float64),\n",
       "  tensor(-2.5640e+27, dtype=torch.float64)])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model_gaussian(input_torch, mu, sigma, p_t_tensor, num_classes = 10):\n",
    "    #assumes that the input comes in a row\n",
    "    input_torch_reshaped = input_torch.view(input_torch.shape[0], -1)\n",
    "    \n",
    "    # Estimacion de la probabilidad de verisimilitud para todas las clases\n",
    "    p_gaussian_estimated = evaluate_gaussian_log(mu, sigma, input_torch_reshaped)\n",
    "\n",
    "    p_posterior_all = []\n",
    "    for k in range(num_classes):\n",
    "        # Estimacion de la probabilidad posterior\n",
    "        p_posterior_all.append(p_gaussian_estimated[:, k].sum(dim=0) + torch.log(p_t_tensor[k]))\n",
    "        \n",
    "    scores_classes = p_posterior_all\n",
    "    predicted_label = max(p_posterior_all)\n",
    "       \n",
    "    return(predicted_label, scores_classes)\n",
    "\n",
    "new_image_gaus = load_single_image(img_index = 65, mode=\"gray\") #Numero 1\n",
    "#print(new_img.shape)\n",
    "test_model_gaussian(new_image_gaus, mu_all, sigma_all, p_t_tensor, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #Classifies the sample as the class that results in the largest P(Y|X) (posterior)\n",
    "        \n",
    "        posteriors = []\n",
    "        #Go through list of classes\n",
    "        for i, c in enumerate(self.classes):\n",
    "             #Initialize posterior as prior\n",
    "            posterior = self._calculate_prior(c)\n",
    "            # Naive assumption (independence):\n",
    "            # P(x1,x2,x3|Y) = P(x1|Y)*P(x2|Y)*P(x3|Y)\n",
    "            # Posterior is product of prior and likelihoods (ignoring scaling factor)\n",
    "            for feature_value, params in zip(sample, self.parameters[i]):\n",
    "                # Likelihood of feature value given distribution of feature values given y\n",
    "                likelihood = self._calculate_likelihood(params[\"mean\"], params[\"var\"], feature_value)\n",
    "                posterior *= likelihood\n",
    "            posteriors.append(posterior)\n",
    "        # Return the class with the largest posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Test Model batch Function: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def test_model_batch(test_set, labels, p_m_pix_val_given_k, p_t_tensor):\n",
    "    #TODO IMPLEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *II Sección: Prueba del Modelo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_d_1_t_1  tensor(2.4102e-43)\n",
      "score_d_2_t_1  tensor(0.)\n",
      "score_d_1_t_0  tensor(0.0574)\n",
      "score_d_2_t_0  tensor(0.1119)\n"
     ]
    }
   ],
   "source": [
    "score_d_1_t_1 = evaluate_gaussian(mu = 20.25, sigma = 0.95, x = 7)\n",
    "score_d_2_t_1 = evaluate_gaussian(mu = 59.75, sigma = 1.25, x = 17)\n",
    "print(\"score_d_1_t_1 \", score_d_1_t_1)\n",
    "print(\"score_d_2_t_1 \", score_d_2_t_1)\n",
    "score_d_1_t_0 = evaluate_gaussian(mu = 5.5, sigma = 0.7, x = 7)\n",
    "score_d_2_t_0 = evaluate_gaussian(mu = 17.5, sigma = 3.53, x = 17)\n",
    "print(\"score_d_1_t_0 \", score_d_1_t_0)\n",
    "print(\"score_d_2_t_0 \", score_d_2_t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
