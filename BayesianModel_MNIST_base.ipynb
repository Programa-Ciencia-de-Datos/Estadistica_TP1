{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de la clasificación multi-clase con Bayes ingenuo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga de las imágenes- mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def binarize_image(image_tensor):\n",
    "    image_tensor[image_tensor > 0.5] = 1\n",
    "    image_tensor[image_tensor <= 0.5] = 0\n",
    "    return image_tensor\n",
    "\n",
    "def imshow(image_tensor):\n",
    "    im = plt.imshow(image_tensor.numpy(), cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def load_dataset(path = \"mnist_dataset/train\"):\n",
    "    #Open up the dataset\n",
    "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
    "    #print(dataset)\n",
    "    list_images = dataset.imgs\n",
    "    #print(list_images)\n",
    "    train_data_tensor  = None \n",
    "    train_data_tensor_gray = None\n",
    "    labels_training = []\n",
    "    first_tensor = True\n",
    "    #list_images_training =  set(data_labeled.train_ds.x.items)\n",
    "    #print(list_images)\n",
    "    for i in range(len(list_images)):\n",
    "        pair_path_label = list_images[i]\n",
    "        image = Image.open(pair_path_label[0])        \n",
    "\n",
    "        x_tensor = TF.to_tensor(image).squeeze() #Return tensor in range [0.0 - 1.0]\n",
    "        x_tensor_gray = TF.pil_to_tensor(image).squeeze() #Return tensor in grayscale\n",
    "        x_tensor_bin = binarize_image(x_tensor)\n",
    "               \n",
    "        #plt.figure()\n",
    "        #plt.imshow(x_tensor_bin)\n",
    "        x_tensor_bin_plain = x_tensor_bin.view(x_tensor_bin.shape[0] * x_tensor_bin.shape[1], -1)\n",
    "        x_tensor_gray_plain = x_tensor_gray.view(x_tensor_gray.shape[0] * x_tensor_gray.shape[1], -1)\n",
    "        #print(\"tensor \", x_tensor_bin_plain)\n",
    "        #test dataset case        \n",
    "        #if(\"train\" in pair_path_label[0]):\n",
    "        labels_training += [pair_path_label[1]]\n",
    "        #print(pair_path_label)\n",
    "        if(first_tensor):\n",
    "            first_tensor = False\n",
    "            train_data_tensor = x_tensor_bin_plain\n",
    "            train_data_tensor_gray = x_tensor_gray_plain\n",
    "        else:\n",
    "            train_data_tensor = torch.cat((train_data_tensor, x_tensor_bin_plain), 1)  \n",
    "            train_data_tensor_gray = torch.cat((train_data_tensor_gray, x_tensor_gray_plain), 1)\n",
    "    return (train_data_tensor, train_data_tensor_gray, torch.tensor(labels_training))       \n",
    "\n",
    "(train_data_tensor, train_data_tensor_gray, labels_training) = load_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train gray dimensions torch.Size([784, 600])\n",
      "train bin dimensions  torch.Size([784, 600])\n",
      "train labels  600\n",
      "p_m_0_given_k_acc =  torch.Size([784, 10])\n",
      "p_m_1_given_k_acc =  torch.Size([784, 10])\n",
      "p_t_tensor_acc =  torch.Size([10])\n",
      "gaussian_given_k_acc =  torch.Size([784, 600])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g3/jnbbw4bs1cqc87xtx7hgyr5w0000gn/T/ipykernel_24247/2020273718.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  coef_norm = 1 / (torch.sqrt(torch.tensor(2.0 * torch.pi * sigma ** 2)))\n",
      "/var/folders/g3/jnbbw4bs1cqc87xtx7hgyr5w0000gn/T/ipykernel_24247/2020273718.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return coef_norm * torch.exp(torch.tensor(-0.5*((mu - x)/sigma )** 2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([0.9500, 1.0000, 0.9333, 0.8000, 1.0000, 0.9500, 1.0000, 0.9667, 0.9000,\n",
       "          1.0000]),\n",
       "  tensor([0.0500, 0.0000, 0.0667, 0.2000, 0.0000, 0.0500, 0.0000, 0.0333, 0.1000,\n",
       "          0.0000])],\n",
       " tensor([8.9287e-03, 8.9287e-03, 8.9287e-03, 9.3870e-03, 2.4916e-04, 1.0749e-06,\n",
       "         8.9287e-03, 9.5478e-03, 1.9093e-03, 8.9287e-03, 3.2182e-03, 6.3353e-03,\n",
       "         8.9287e-03, 8.9287e-03, 8.9287e-03, 8.9287e-03, 9.2537e-03, 9.6279e-03,\n",
       "         8.9287e-03, 8.9287e-03, 9.2537e-03, 9.6279e-03, 9.5478e-03, 8.9287e-03,\n",
       "         9.6279e-03, 9.7292e-03, 9.4459e-03, 9.3229e-03, 8.9287e-03, 9.1795e-03,\n",
       "         8.9287e-03, 8.9287e-03, 9.3229e-03, 8.9287e-03, 9.1006e-03, 9.3870e-03,\n",
       "         9.6596e-03, 8.9287e-03, 9.5478e-03, 8.9287e-03, 8.9287e-03, 1.0074e-05,\n",
       "         9.4478e-03, 8.9287e-03, 3.4409e-04, 9.0169e-03, 8.9287e-03, 8.9287e-03,\n",
       "         9.6279e-03, 9.4459e-03, 9.4996e-03, 9.0169e-03, 8.9287e-03, 8.9287e-03,\n",
       "         8.9287e-03, 8.9287e-03, 8.9287e-03, 8.9287e-03, 8.9287e-03, 8.9287e-03,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 5.1638e-08, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 2.0971e-07, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         1.0412e-01, 5.6263e-02, 1.0412e-01, 1.0412e-01, 1.0412e-01, 1.0412e-01,\n",
       "         6.4622e-03, 6.5306e-03, 6.4255e-03, 6.3872e-03, 3.6121e-03, 6.6199e-03,\n",
       "         6.6199e-03, 6.3872e-03, 4.1739e-03, 6.3872e-03, 6.3872e-03, 6.3872e-03,\n",
       "         6.3872e-03, 6.3872e-03, 6.3872e-03, 2.4912e-06, 6.3872e-03, 2.2044e-03,\n",
       "         6.3872e-03, 6.3872e-03, 6.5919e-03, 6.3872e-03, 6.3872e-03, 6.3872e-03,\n",
       "         6.6199e-03, 6.4255e-03, 6.7490e-03, 6.3872e-03, 6.7638e-03, 6.3872e-03,\n",
       "         9.9157e-04, 6.3872e-03, 6.3872e-03, 6.3872e-03, 5.5127e-06, 6.3872e-03,\n",
       "         6.3872e-03, 6.3872e-03, 6.4972e-03, 6.7966e-03, 6.3872e-03, 6.6929e-03,\n",
       "         6.3872e-03, 6.3872e-03, 6.3872e-03, 6.3872e-03, 4.2502e-06, 6.3872e-03,\n",
       "         6.3872e-03, 6.4255e-03, 6.3872e-03, 6.4972e-03, 6.3872e-03, 6.3872e-03,\n",
       "         6.3872e-03, 6.3872e-03, 6.3872e-03, 6.3872e-03, 6.6704e-03, 6.5306e-03,\n",
       "         4.0572e-03, 4.8260e-03, 4.0572e-03, 6.9421e-04, 4.0572e-03, 4.0572e-03,\n",
       "         4.0572e-03, 4.0572e-03, 4.5768e-03, 4.0572e-03, 4.0572e-03, 4.0572e-03,\n",
       "         4.0572e-03, 4.2050e-03, 4.3154e-03, 4.5558e-03, 3.7334e-03, 4.0572e-03,\n",
       "         4.2050e-03, 2.0626e-04, 3.2235e-04, 4.0572e-03, 3.6310e-03, 3.0231e-03,\n",
       "         4.0572e-03, 4.0572e-03, 4.5121e-03, 4.0572e-03, 4.1175e-03, 3.3169e-04,\n",
       "         2.2700e-03, 2.0626e-04, 3.0959e-03, 4.1762e-03, 4.2611e-03, 4.4662e-03,\n",
       "         4.4894e-03, 4.0572e-03, 4.0572e-03, 4.0572e-03, 1.5083e-03, 4.0572e-03,\n",
       "         4.0572e-03, 4.0875e-03, 4.0572e-03, 4.0572e-03, 4.8043e-03, 2.0626e-04,\n",
       "         4.0572e-03, 4.0572e-03, 1.1416e-03, 4.0572e-03, 4.0572e-03, 4.2885e-03,\n",
       "         4.8533e-03, 4.0572e-03, 3.9943e-03, 2.8772e-03, 4.6720e-03, 4.0572e-03,\n",
       "         8.3481e-02, 8.3481e-02, 7.7968e-08, 8.3481e-02, 6.1415e-03, 8.3481e-02,\n",
       "         8.3481e-02, 8.3481e-02, 8.0359e-02, 8.3481e-02, 8.9395e-02, 8.3481e-02,\n",
       "         5.7716e-02, 8.3481e-02, 5.7716e-02, 8.3481e-02, 8.0359e-02, 8.3481e-02,\n",
       "         8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02,\n",
       "         8.3481e-02, 3.3671e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 6.1415e-03,\n",
       "         8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 8.0359e-02, 8.3481e-02,\n",
       "         8.3481e-02, 9.0879e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02,\n",
       "         8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 4.5245e-02, 8.3481e-02,\n",
       "         8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02, 8.3481e-02,\n",
       "         9.0879e-02, 8.3481e-02, 8.7707e-02, 8.3481e-02, 3.5244e-03, 8.3481e-02,\n",
       "         7.4800e-03, 7.4800e-03, 7.4800e-03, 7.7075e-03, 7.4800e-03, 7.5668e-03,\n",
       "         7.5668e-03, 7.8529e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03,\n",
       "         3.9005e-07, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 4.8166e-05,\n",
       "         7.8494e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.5247e-03,\n",
       "         7.4800e-03, 3.5406e-03, 7.4800e-03, 7.6766e-03, 7.4800e-03, 7.4800e-03,\n",
       "         7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03,\n",
       "         7.4800e-03, 7.7356e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.4800e-03,\n",
       "         7.7356e-03, 1.7446e-07, 7.4800e-03, 7.4800e-03, 7.4800e-03, 7.7356e-03,\n",
       "         7.7608e-03, 7.6061e-03, 7.7356e-03, 7.5668e-03, 7.7830e-03, 3.5406e-03,\n",
       "         7.4800e-03, 7.7356e-03, 7.4800e-03, 7.4800e-03, 7.8480e-03, 7.4800e-03,\n",
       "         2.0426e-01, 2.0426e-01, 1.6452e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         2.0426e-01, 2.1246e-01, 2.1246e-01, 2.0426e-01, 1.6452e-01, 7.0833e-06,\n",
       "         2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         2.0426e-01, 1.6452e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         2.0426e-01, 2.0426e-01, 7.2181e-05, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         2.0426e-01, 2.0426e-01, 2.0426e-01, 1.6452e-01, 2.0426e-01, 2.0426e-01,\n",
       "         1.3003e-02, 2.0426e-01, 2.0426e-01, 2.0426e-01, 3.0926e-03, 2.0426e-01,\n",
       "         2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01, 2.0426e-01,\n",
       "         1.5143e-02, 1.5143e-02, 1.5259e-02, 7.6931e-03, 1.5143e-02, 1.5143e-02,\n",
       "         1.5674e-07, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.8051e-09, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5259e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.4681e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02, 1.5143e-02,\n",
       "         5.6774e-05, 6.8096e-04, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03,\n",
       "         6.5129e-03, 6.5129e-03, 6.5129e-03, 6.6052e-03, 6.5129e-03, 6.5129e-03,\n",
       "         6.5129e-03, 6.8096e-04, 6.5129e-03, 7.7174e-06, 6.5129e-03, 6.5129e-03,\n",
       "         6.5129e-03, 6.1676e-03, 6.5129e-03, 6.5129e-03, 3.5322e-04, 6.5129e-03,\n",
       "         7.0631e-03, 6.5129e-03, 1.7158e-03, 7.0737e-03, 6.6486e-03, 6.5129e-03,\n",
       "         6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03,\n",
       "         6.8039e-03, 6.8379e-03, 6.5129e-03, 1.8610e-04, 6.5129e-03, 6.5129e-03,\n",
       "         6.9276e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03,\n",
       "         6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03,\n",
       "         2.7279e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03, 6.5129e-03,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02,\n",
       "         4.1575e-02, 4.1575e-02, 3.9500e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 1.7998e-14, 4.1575e-02, 4.1575e-02,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1691e-02,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1691e-02, 4.1575e-02,\n",
       "         4.1575e-02, 3.7810e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02,\n",
       "         3.9500e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02,\n",
       "         4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02, 4.1575e-02],\n",
       "        dtype=torch.float64),\n",
       " tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate_gaussian(mu, sigma, x):\n",
    "    coef_norm = 1 / (torch.sqrt(torch.tensor(2.0 * torch.pi * sigma ** 2)))\n",
    "    return coef_norm * torch.exp(torch.tensor(-0.5*((mu - x)/sigma )** 2))    \n",
    "\n",
    "def train_model(train_data_tensor_bin, train_data_tensor_gray, labels_training, num_classes = 10):\n",
    "\n",
    "    first_tensor = True\n",
    "    p_t_tensor_acc = None\n",
    "    p_m_1_given_k_acc = None\n",
    "    p_m_0_given_k_acc = None\n",
    "    gaussian_given_k_acc = None\n",
    "    #print(train_data_tensor_gray[650, 0:60])\n",
    "    \n",
    "    for k in range(num_classes):\n",
    "        # Filtra train_data_tensor por clase para dataset binarizado y en escala de grises\n",
    "        train_data_tensor_bin_per_k = train_data_tensor_bin[:, labels_training == k].type(torch.int64)\n",
    "        train_data_tensor_gray_per_k = train_data_tensor_gray[:, labels_training == k].type(torch.float64)\n",
    "        #print(train_data_tensor_bin_per_k)\n",
    "        #print(train_data_tensor_gray_per_k)\n",
    "        \n",
    "        # D = cantidad de filas (784 pixeles)\n",
    "        # N = cantidad de columnas (600 imágenes)\n",
    "        D, N = train_data_tensor_bin.shape\n",
    "        \n",
    "        # Estimacion de probabilidad a priori\n",
    "        p_t_tensor = torch.tensor([train_data_tensor_bin_per_k.shape[1] / N])\n",
    "        #print(p_t_tensor)\n",
    "        \n",
    "        # Estimacion de verisimilitud para cada pixel por clase\n",
    "        p_m_1_given_k = (train_data_tensor_bin_per_k == 1).sum(dim=1)/train_data_tensor_bin_per_k.shape[1]\n",
    "        #print(p_m_pix_val_given_k)\n",
    "        \n",
    "        # Transforma tensor de verisimilitud a una sola columna\n",
    "        p_m_1_given_k = p_m_1_given_k.view(p_m_1_given_k.shape[0], -1)\n",
    "        #print(p_m_pix_val_given_k)\n",
    "    \n",
    "        # Calculo de media y desviacion estandar\n",
    "        mu_given_k = torch.mean(train_data_tensor_gray_per_k, dim=1)\n",
    "        sigma_given_k = torch.std(train_data_tensor_gray_per_k, dim=1)+1e-12\n",
    "        #print(mu_given_k.shape)\n",
    "        #print(sigma_given_k.shape)\n",
    "        \n",
    "        # Transforma tensor de mu y sigma a una sola columna\n",
    "        mu_given_k = mu_given_k.view(mu_given_k.shape[0], -1)\n",
    "        sigma_given_k = sigma_given_k.view(sigma_given_k.shape[0], -1)\n",
    "        #print(mu_given_k)\n",
    "        \n",
    "        # Estimacion de funcion de densidad de probabilidad\n",
    "        gaussian_given_k = evaluate_gaussian(mu_given_k, sigma_given_k, train_data_tensor_gray_per_k)\n",
    "        #print(p_gaussian)\n",
    "    \n",
    "        if(first_tensor):\n",
    "            first_tensor = False\n",
    "            p_m_1_given_k_acc = p_m_1_given_k\n",
    "            p_t_tensor_acc = p_t_tensor\n",
    "            gaussian_given_k_acc = gaussian_given_k\n",
    "        else:\n",
    "            p_m_1_given_k_acc = torch.cat((p_m_1_given_k_acc, p_m_1_given_k), 1)\n",
    "            p_t_tensor_acc = torch.cat((p_t_tensor_acc, p_t_tensor), 0)\n",
    "            gaussian_given_k_acc = torch.cat((gaussian_given_k_acc, gaussian_given_k), 1)\n",
    "\n",
    "    # Saca complemento de p_m_1_given_k_acc\n",
    "    p_m_0_given_k_acc = 1 - p_m_1_given_k_acc\n",
    "    \n",
    "    print(\"p_m_0_given_k_acc = \", p_m_0_given_k_acc.shape)\n",
    "    print(\"p_m_1_given_k_acc = \", p_m_1_given_k_acc.shape)\n",
    "    print(\"p_t_tensor_acc = \", p_t_tensor_acc.shape)\n",
    "    print(\"gaussian_given_k_acc = \", gaussian_given_k_acc.shape)\n",
    "        \n",
    "    return (list([p_m_0_given_k_acc[650], p_m_1_given_k_acc[650]]), gaussian_given_k_acc[650], p_t_tensor_acc)\n",
    "\n",
    "print(\"train gray dimensions\", train_data_tensor_gray.shape)\n",
    "print(\"train bin dimensions \", train_data_tensor.shape)\n",
    "print(\"train labels \", len(labels_training))\n",
    "\n",
    "train_model(train_data_tensor, train_data_tensor_gray, labels_training)\n",
    "\n",
    "#train model by calculating the prior probabilities\n",
    "#(p_m_pix_val_given_k, p_t_tensor) = train_model(train_data_tensor, labels_training)\n",
    "#print(\"p_m_pix_val_given_k size \", p_m_pix_val_given_k.shape)\n",
    "#(predicted_label, scores_classes) = test_model(train_data_tensor[:, 500], p_m_pix_val_given_k, p_t_tensor)\n",
    "#print(\"predicted_label \", predicted_label)\n",
    "#print(\"real label \", labels_training[500])\n",
    "#acc = test_model_batch(train_data_tensor, labels_training, p_m_pix_val_given_k, p_t_tensor)\n",
    "#print(\"Model accuracy \", acc)\n",
    "     \n",
    "    \n",
    "\n",
    "#def test_model_batch(test_set, labels, p_m_pix_val_given_k, p_t_tensor):\n",
    "    #TODO IMPLEMENT\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test Gaussian Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(input_torch,p_t_tensor_acc,gaussian_given_k_acc, num_classes = 10):\n",
    "    Probabilities: \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test Bernoulli Model Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Test Model batch Function: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
