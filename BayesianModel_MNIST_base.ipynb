{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train gray dimensions torch.Size([784, 600])\n",
      "train dimensions  torch.Size([784, 600])\n",
      "train labels  600\n",
      "Values matched: tensor([0., 1.])\n",
      "Counts: tensor([57,  3])\n",
      "p_m_pix_val_given_k =  tensor(0.0500)\n",
      "Values matched: tensor([0.])\n",
      "Counts: tensor([60])\n",
      "p_m_pix_val_given_k =  tensor(0.)\n",
      "Values matched: tensor([0., 1.])\n",
      "Counts: tensor([56,  4])\n",
      "p_m_pix_val_given_k =  tensor(0.0667)\n",
      "Values matched: tensor([0., 1.])\n",
      "Counts: tensor([48, 12])\n",
      "p_m_pix_val_given_k =  tensor(0.2000)\n",
      "Values matched: tensor([0.])\n",
      "Counts: tensor([60])\n",
      "p_m_pix_val_given_k =  tensor(0.)\n",
      "Values matched: tensor([0., 1.])\n",
      "Counts: tensor([57,  3])\n",
      "p_m_pix_val_given_k =  tensor(0.0500)\n",
      "Values matched: tensor([0.])\n",
      "Counts: tensor([60])\n",
      "p_m_pix_val_given_k =  tensor(0.)\n",
      "Values matched: tensor([0., 1.])\n",
      "Counts: tensor([58,  2])\n",
      "p_m_pix_val_given_k =  tensor(0.0333)\n",
      "Values matched: tensor([0., 1.])\n",
      "Counts: tensor([54,  6])\n",
      "p_m_pix_val_given_k =  tensor(0.1000)\n",
      "Values matched: tensor([0.])\n",
      "Counts: tensor([60])\n",
      "p_m_pix_val_given_k =  tensor(0.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.),\n",
       " tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate_gaussian(mu, sigma, x):\n",
    "    coef_norm = 1 / (torch.sqrt(torch.tensor(2.0 * torch.pi * sigma ** 2)))\n",
    "    return coef_norm * torch.exp(torch.tensor(-0.5*((mu - x)/sigma )** 2))\n",
    "    \n",
    "\n",
    "def binarize_image(image_tensor):\n",
    "    image_tensor[image_tensor > 0.5] = 1\n",
    "    image_tensor[image_tensor <= 0.5] = 0\n",
    "    return image_tensor\n",
    "\n",
    "def imshow(image_tensor):\n",
    "    im = plt.imshow(image_tensor.numpy(), cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "#def test_model(input_torch, p_m_pix_val_given_k, p_t_tensor, num_classes = 10):\n",
    "    #assumes that the input comes in a row\n",
    "    #TODO IMPLEMENT\n",
    "    #return (predicted_label, scores_classes)\n",
    "\n",
    "#def test_model_batch(test_set, labels, p_m_pix_val_given_k, p_t_tensor):\n",
    "    #TODO IMPLEMENT\n",
    "\n",
    "def train_model(train_data_tensor, labels_training, num_classes = 10):\n",
    "    _, labels_counts = torch.unique(labels_training, return_counts=True)\n",
    "    p_t_tensor = labels_counts / labels_training.shape[0]\n",
    "    #p_t_tensor 1 x 10\n",
    "    \n",
    "    #matched_values, counts = torch.unique(train_data_tensor[783,0:60], return_counts=True)\n",
    "    #print(\"Values matched: %s\\nCounts: %s\" %(matched_values, counts))\n",
    "    #result = counts/60\n",
    "    #print(\"p_m_pix_val_given_k = \", result)\n",
    "    first_tensor = True\n",
    "    p_m_pix_val_given_k = None\n",
    "    \n",
    "    for img_index in range(0, num_classes * 60, 60):\n",
    "        matched_values, counts = torch.unique(train_data_tensor[650,img_index:img_index+60], return_counts=True)\n",
    "        print(\"Values matched: %s\\nCounts: %s\" %(matched_values, counts))\n",
    "        \n",
    "        if(matched_values[0] == 0):\n",
    "            p_m = 1 - counts[0]/60\n",
    "        else:\n",
    "            p_m = counts[0]/60\n",
    "        \n",
    "        p_m_pix_val_given_k = p_m\n",
    "        \n",
    "        #if(first_tensor):\n",
    "            #first_tensor = False\n",
    "            #p_m_pix_val_given_k = p_m\n",
    "        #else:\n",
    "            #p_m_pix_val_given_k = torch.cat((p_m_pix_val_given_k, p_m), 1)\n",
    "            \n",
    "        print(\"p_m_pix_val_given_k = \", p_m_pix_val_given_k)\n",
    "    \n",
    "    #p_m_pix_val_given_k\n",
    "    \n",
    "    return (p_m_pix_val_given_k, p_t_tensor)\n",
    "\n",
    "def load_dataset(path = \"src_base/mnist_dataset/train\"):\n",
    "    #Open up the dataset\n",
    "    dataset =  torchvision.datasets.ImageFolder(path)   \n",
    "    #print(dataset)\n",
    "    list_images = dataset.imgs\n",
    "    #print(list_images)\n",
    "    train_data_tensor  = None \n",
    "    train_data_tensor_gray = None\n",
    "    labels_training = []\n",
    "    first_tensor = True\n",
    "    #list_images_training =  set(data_labeled.train_ds.x.items)\n",
    "    #print(list_images)\n",
    "    for i in range(len(list_images)):\n",
    "        pair_path_label = list_images[i]\n",
    "        image = Image.open(pair_path_label[0])        \n",
    "\n",
    "        x_tensor = TF.to_tensor(image).squeeze() #Return tensor in range [0.0 - 1.0]\n",
    "        x_tensor_gray = TF.pil_to_tensor(image).squeeze() #Return tensor in grayscale\n",
    "        x_tensor_bin = binarize_image(x_tensor)\n",
    "               \n",
    "        #plt.figure()\n",
    "        #plt.imshow(x_tensor_bin)\n",
    "        x_tensor_bin_plain = x_tensor_bin.view(x_tensor_bin.shape[0] * x_tensor_bin.shape[1], -1)\n",
    "        x_tensor_gray_plain = x_tensor_gray.view(x_tensor_gray.shape[0] * x_tensor_gray.shape[1], -1)\n",
    "        #print(\"tensor \", x_tensor_bin_plain)\n",
    "        #test dataset case        \n",
    "        #if(\"train\" in pair_path_label[0]):\n",
    "        labels_training += [pair_path_label[1]]\n",
    "        #print(pair_path_label)\n",
    "        if(first_tensor):\n",
    "            first_tensor = False\n",
    "            train_data_tensor = x_tensor_bin_plain\n",
    "            train_data_tensor_gray = x_tensor_gray_plain\n",
    "        else:\n",
    "            train_data_tensor = torch.cat((train_data_tensor, x_tensor_bin_plain), 1)  \n",
    "            train_data_tensor_gray = torch.cat((train_data_tensor_gray, x_tensor_gray_plain), 1)\n",
    "    return (train_data_tensor, train_data_tensor_gray, torch.tensor(labels_training))       \n",
    "\n",
    "(train_data_tensor, train_data_tensor_gray, labels_training) = load_dataset()\n",
    "\n",
    "print(\"train gray dimensions\", train_data_tensor_gray.shape)\n",
    "print(\"train dimensions \", train_data_tensor.shape)\n",
    "print(\"train labels \", len(labels_training))\n",
    "\n",
    "train_model(train_data_tensor, labels_training)\n",
    "\n",
    "#train model by calculating the prior probabilities\n",
    "#(p_m_pix_val_given_k, p_t_tensor) = train_model(train_data_tensor, labels_training)\n",
    "#print(\"p_m_pix_val_given_k size \", p_m_pix_val_given_k.shape)\n",
    "#(predicted_label, scores_classes) = test_model(train_data_tensor[:, 500], p_m_pix_val_given_k, p_t_tensor)\n",
    "#print(\"predicted_label \", predicted_label)\n",
    "#print(\"real label \", labels_training[500])\n",
    "#acc = test_model_batch(train_data_tensor, labels_training, p_m_pix_val_given_k, p_t_tensor)\n",
    "#print(\"Model accuracy \", acc)\n",
    "    \n",
    "\n",
    "               \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_d_1_t_1  tensor(2.4102e-43)\n",
      "score_d_2_t_1  tensor(0.)\n",
      "score_d_1_t_0  tensor(0.0574)\n",
      "score_d_2_t_0  tensor(0.1119)\n"
     ]
    }
   ],
   "source": [
    "score_d_1_t_1 = evaluate_gaussian(mu = 20.25, sigma = 0.95, x = 7)\n",
    "score_d_2_t_1 = evaluate_gaussian(mu = 59.75, sigma = 1.25, x = 17)\n",
    "print(\"score_d_1_t_1 \", score_d_1_t_1)\n",
    "print(\"score_d_2_t_1 \", score_d_2_t_1)\n",
    "score_d_1_t_0 = evaluate_gaussian(mu = 5.5, sigma = 0.7, x = 7)\n",
    "score_d_2_t_0 = evaluate_gaussian(mu = 17.5, sigma = 3.53, x = 17)\n",
    "print(\"score_d_1_t_0 \", score_d_1_t_0)\n",
    "print(\"score_d_2_t_0 \", score_d_2_t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
